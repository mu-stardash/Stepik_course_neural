{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f0a50e",
   "metadata": {},
   "source": [
    "# Pictures Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857cfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# init (so our exps can be replayed)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c41be0",
   "metadata": {},
   "source": [
    "# Dataset for pics (MNIST)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "190c9116",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bbe4d787774b20838745363b4fcfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02fe93b735d459c8392952910e3573f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e2d270575243278412fc09eab3a629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eaeb5eeb4242a7a156cea510cbbae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n"
     ]
    }
   ],
=======
   "execution_count": 2,
   "id": "190c9116",
   "metadata": {},
   "outputs": [],
>>>>>>> 833f8a7 (End)
   "source": [
    "import torchvision.datasets\n",
    "# download train and test pictures from dataset\n",
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 3,
>>>>>>> 833f8a7 (End)
   "id": "3d92b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MNIST_train.data\n",
    "y_train = MNIST_train.targets\n",
    "X_test = MNIST_test.data\n",
    "y_test = MNIST_test.targets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 4,
>>>>>>> 833f8a7 (End)
   "id": "aa3f50fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.uint8, torch.int64)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 41,
=======
     "execution_count": 4,
>>>>>>> 833f8a7 (End)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the type? X_train - pictures, y_train - labels\n",
    "X_train.dtype, y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": 5,
>>>>>>> 833f8a7 (End)
   "id": "800b7621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "torch.Size([60000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# let's make everything in float type\n",
    "X_train = X_train.float()\n",
    "X_test = X_test.float()\n",
    "# and what on the size of datasets: 28x28 - pictures size\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 6,
>>>>>>> 833f8a7 (End)
   "id": "821dfc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# let's see how out pictures look like\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[5, :, :])\n",
    "plt.show()\n",
    "print(y_train[5])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 7,
>>>>>>> 833f8a7 (End)
   "id": "be70adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# растянем картинки в один вектор (так как каждая картинка описывает двумерным тензором, надо исправить)\n",
    "X_train = X_train.reshape([-1, 28 * 28])\n",
    "X_test = X_test.reshape([-1, 28 * 28])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 8,
>>>>>>> 833f8a7 (End)
   "id": "d64c3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "class MNISTNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10) \n",
    "    \n",
    "    # пропускает х через все слои\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "mnist_net = MNISTNet(100)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 9,
>>>>>>> 833f8a7 (End)
   "id": "21b5d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need loss function and optimizer for gradient diecent\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
=======
   "execution_count": 10,
>>>>>>> 833f8a7 (End)
   "id": "4f0a2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 28, 28])\n",
      "torch.Size([784, 6000])\n",
      "torch.Size([28, 6000, 28])\n",
      "torch.Size([4704000])\n",
      "torch.Size([4704000, 1, 1])\n",
      "torch.Size([1500, 14, 32, 7])\n"
     ]
    }
   ],
   "source": [
    "# Answer on the task\n",
    "x = torch.ones([6000, 28, 28], dtype=torch.int32)\n",
    "print(x.shape)\n",
    "#print(x.reshape(-1, 9).shape)\n",
    "print(x.reshape(-1,6000).shape)\n",
    "print(x.reshape(len(x[1]), len(x), len(x[2])).shape)\n",
    "print(x.reshape(-1).shape)\n",
    "print(x.reshape(-1,1,1).shape)\n",
    "print(x.reshape(-1,14,32,7).shape)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "markdown",
   "id": "74724f9b",
   "metadata": {},
   "source": [
    "# Process of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e778b00",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9084)\n",
      "tensor(0.9171)\n",
      "tensor(0.9109)\n",
      "tensor(0.9209)\n",
      "tensor(0.9235)\n",
      "tensor(0.9295)\n",
      "tensor(0.9264)\n",
      "tensor(0.9329)\n",
      "tensor(0.9307)\n",
      "tensor(0.9273)\n",
      "tensor(0.9300)\n",
      "tensor(0.9286)\n",
      "tensor(0.9349)\n",
      "tensor(0.9349)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18448\\2401531890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# we will also make a prediction on test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             adam(params_with_grad,\n\u001b[0m\u001b[0;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# батчевый (стахостический) град спуск\n",
    "batch_size = 100\n",
    "\n",
    "# test_accuracy_history = []\n",
    "# test_loss_history = []\n",
    "\n",
    "# X_test = X_test.to(device)\n",
    "# y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # mix dataset\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    \n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        \n",
    "        X_batch = X_train[batch_indexes] #.to(device)\n",
    "        y_batch = y_train[batch_indexes] #.to(device)\n",
    "        \n",
    "        preds = mnist_net.forward(X_batch) \n",
    "        \n",
    "        loss_value = loss(preds, y_batch)\n",
    "        # count gradients\n",
    "        loss_value.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    # we will also make a prediction on test dataset\n",
    "    test_preds = mnist_net.forward(X_test)\n",
    "#     test_loss_history.append(loss(test_preds, y_test))\n",
    "    \n",
    "    # argmax give the number of neuron with max amount\n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean()\n",
    "#     test_accuracy_history.append(accuracy)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d335b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": []
>>>>>>> 833f8a7 (End)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
