{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c7d1a4",
   "metadata": {},
   "source": [
    "На этом уроке мы с вами реализуем прямой проход сверточного слоя, обратный проход и расчет производных мы трогать не будем.\n",
    "\n",
    "Вспомним как работает сверточный слой:\n",
    "\n",
    "- на вход подается массив изображений, еще он называется батчем\n",
    "\n",
    "- к каждому изображению по границам добавляются нули\n",
    "\n",
    "- по каждому изображению \"скользит\" каждый из фильтров сверточного слоя\n",
    "\n",
    "Давайте начнем с разминки - реализуем функцию, добавляющую padding.\n",
    "\n",
    "Пусть у нас есть батч input_images из двух изображений с тремя каналами (RGB). Размер изображений пусть будет 3*3. Вспомним, что вход сверточного слоя имеет следующую размерность:\n",
    "\n",
    "- размер батча\n",
    "\n",
    "- число каналов\n",
    "\n",
    "- высота\n",
    "\n",
    "- ширина\n",
    "\n",
    "В рассматриваемом случае размерность входа (2, 3, 3, 3).\n",
    "\n",
    "Если мы добавим вокруг каждого изображения отступ из одного нуля, то размер каждого изображений станет 3+2*1 = 5 пикселей в ширину и 5 в высоту соответственно (добавляем по одному нулю с каждой стороны изображения).\n",
    "\n",
    "Напишите любую работающую реализацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b59de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8387f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем входной массив из двух изображений RGB 3*3\n",
    "input_images = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "       correct_padded_images = torch.tensor(\n",
    "           [[[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  0.,  1.,  2.,  0.],\n",
    "          [0.,  3.,  4.,  5.,  0.],\n",
    "          [0.,  6.,  7.,  8.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  9., 10., 11.,  0.],\n",
    "          [0., 12., 13., 14.,  0.],\n",
    "          [0., 15., 16., 17.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 18., 19., 20.,  0.],\n",
    "          [0., 21., 22., 23.,  0.],\n",
    "          [0., 24., 25., 26.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]],\n",
    "\n",
    "\n",
    "        [[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 27., 28., 29.,  0.],\n",
    "          [0., 30., 31., 32.,  0.],\n",
    "          [0., 33., 34., 35.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 36., 37., 38.,  0.],\n",
    "          [0., 39., 40., 41.,  0.],\n",
    "          [0., 42., 43., 44.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 45., 46., 47.,  0.],\n",
    "          [0., 48., 49., 50.,  0.],\n",
    "          [0., 51., 52., 53.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f68a9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding2d(input_images):\n",
    "    p2d = (1, 1, 1, 1)\n",
    "    padded_images = torch.nn.functional.pad(input_images, pad=p2d)\n",
    "    return padded_images.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd80f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "print(torch.allclose(get_padding2d(input_images), correct_padded_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
